{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado de modelos 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook guarda en un archivo csv las transformaciones que hay que realizar a un modelo para alinearlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import pyvista as pv\n",
    "from PIL import Image\n",
    "import vtk\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borrado y creado .csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713724113.404954       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "W0000 00:00:1713724113.410495       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo CSV\n",
    "archivo_csv = \"matrices_transformacion.csv\"\n",
    "\n",
    "if os.path.exists(archivo_csv):\n",
    "    os.remove(archivo_csv)\n",
    "    with open(archivo_csv, mode='w', newline='') as file:\n",
    "        print(\"Borrado y creado .csv\")\n",
    "\n",
    "# Lista de índices de landmarks para nariz, ojos y boca\n",
    "landmark_indices = [130, 27, 243, 23, 463, 257, 359, 253, 168, 61, 11, 291, 16]\n",
    "\n",
    "# Crear un objeto FaceLandmarker\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker.task')\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       running_mode=VisionRunningMode.IMAGE,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para sacar una imagen 2D dado un objeto en 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot(actors, plane, colors = None, textures = None, position = None, window_size = [1024, 768]):\n",
    "    \n",
    "    if position is None:\n",
    "        position = [0.0, 0.0, 0.0]\n",
    "\n",
    "        if plane.lower() == \"xy\" or plane.lower() == \"yx\":\n",
    "            position[2] = 1000.0\n",
    "        elif plane.lower() == \"yz\" or plane.lower() == \"zy\":\n",
    "            position[0] = 1000.0\n",
    "        elif plane.lower() == \"xz\" or plane.lower() == \"zx\":\n",
    "            position[1] = 1000.0 \n",
    "        else:\n",
    "            print(\"ERROR: Wrong plane\", plane)\n",
    "            exit(1)\n",
    "        \n",
    "\n",
    "    plotter = pv.Plotter(off_screen = True, window_size = window_size)\n",
    "    plotter.set_background(\"white\")\n",
    "\n",
    "    if colors is None:\n",
    "        colors = [None] * len(actors)\n",
    "\n",
    "    if textures is None:\n",
    "        textures = [None] * len(actors)\n",
    "\n",
    "    for actor, color, tex  in zip(actors, colors, textures):\n",
    "        _ = plotter.add_mesh(actor, color = color, texture = tex)\n",
    "\n",
    "    plotter.set_position(position)\n",
    "    plotter.set_focus([0.0, 0.0, 0.0])\n",
    "    plotter.enable_parallel_projection()\n",
    "    plotter.parallel_scale = 200\n",
    "\n",
    "    return np.array(plotter.screenshot()), plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para pasar punto 2D a punto 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2d_point_to_3d(pv_mesh, point, plotter):\n",
    "    \n",
    "    coordinate = vtk.vtkCoordinate()\n",
    "    coordinate.SetCoordinateSystemToNormalizedDisplay()\n",
    "\n",
    "    # the system coordinates is normalized, so 0.5 is the half of the image\n",
    "    coordinate.SetValue(point[0], point[1])\n",
    "    world_point = coordinate.GetComputedWorldValue(plotter.renderer)\n",
    "\n",
    "    start = [world_point[0], -world_point[1], 1000]\n",
    "    end = [world_point[0], -world_point[1], -1000]\n",
    "\n",
    "    points, _ = pv_mesh.ray_trace(start, end)\n",
    "\n",
    "    final_point = None\n",
    "\n",
    "    if len(points) > 0:\n",
    "        final_point = points[0]\n",
    "    \n",
    "    coordinate = None # Liberar memoria\n",
    "\n",
    "    return final_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para guardar los puntos en un .pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_pp(output_path, coordenadas_3d):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"<!DOCTYPE PickedPoints>\\n\")\n",
    "        f.write(\"<PickedPoints>\\n\")\n",
    "        i = 0\n",
    "        for idx in coordenadas_3d:\n",
    "            x, y, z = idx[0], idx[1], idx[2]\n",
    "            f.write(\n",
    "                '<point x=\"{}\" y=\"{}\" z=\"{}\" active=\"1\" name=\"{}\" />\\n'.format(\n",
    "                    x, y, z, i\n",
    "                )\n",
    "            )\n",
    "            i += 1\n",
    "        f.write(\"</PickedPoints>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para obtener coordenadas de los puntos clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_coordenadas(obj_file_path, texture_file_path, output_path):\n",
    "    # Obtener la imagen del modelo 3D\n",
    "    pv_mesh = pv.read(obj_file_path)\n",
    "    texture = pv.read_texture(texture_file_path)\n",
    "    screenshot, plotter = take_screenshot([pv_mesh], plane='xy', textures=[texture])\n",
    "    image2 = Image.fromarray(np.uint8(screenshot))\n",
    "    image2.save('modelo_objetivo.png')\n",
    "\n",
    "    # Detectamos los face landmarks de la imagen\n",
    "    imagen = 'modelo_objetivo.png'\n",
    "    image = mp.Image.create_from_file(imagen)\n",
    "    detection_result = detector.detect(image)\n",
    "\n",
    "    puntos = []\n",
    "    for face_landmarks in detection_result.face_landmarks:\n",
    "        for idx in landmark_indices:\n",
    "            landmark = face_landmarks[idx]\n",
    "            # Crear un vector con coordenadas x, y\n",
    "            punto_2d = [landmark.x, landmark.y]\n",
    "            # Agregar el vector a la lista\n",
    "            puntos.append(punto_2d)\n",
    "    \n",
    "    # Calcular la coordenada z\n",
    "    coordenadas_3d = []\n",
    "\n",
    "    for point in puntos:\n",
    "        # Convertir cada punto 2D a 3D utilizando la función proporcionada\n",
    "        converted_point = convert_2d_point_to_3d(pv_mesh, point, plotter)\n",
    "        # Agregar el punto convertido a la lista\n",
    "        coordenadas_3d.append(converted_point)\n",
    "        \n",
    "    # print(\"Coordenadas 3D resultantes:\", coordenadas_3d)\n",
    "    guardar_pp(output_path, coordenadas_3d)\n",
    "\n",
    "    # Liberar memoria\n",
    "    pv_mesh = None\n",
    "    image = None\n",
    "    image2 = None\n",
    "    plotter = None\n",
    "\n",
    "    return coordenadas_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para guardar una matriz en el archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_matriz_en_csv(nombre, matriz, archivo_csv):\n",
    "    if not isinstance(matriz, np.ndarray):\n",
    "        raise TypeError(\"La matriz debe ser una lista de listas\")\n",
    "    \n",
    "    try:\n",
    "        # Apertura del archivo en modo append ('a')\n",
    "        with open(archivo_csv, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            valores_matriz = [valor for fila in matriz for valor in fila]\n",
    "            writer.writerow([nombre] + valores_matriz)\n",
    "    except IOError as e:\n",
    "        print(f\"Error al escribir en el archivo CSV: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener puntos clave modelo referencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo de referencia 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo .obj\n",
    "obj_file_path = 'referencia H3DS-net/referencia.obj'\n",
    "texture_file_path = 'referencia H3DS-net/referencia.png'\n",
    "pp_file_path = 'referencia H3DS-net/referencia.pp'\n",
    "\n",
    "coord_ref = obtener_coordenadas(obj_file_path, texture_file_path, pp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener matriz de transformación para otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivansalinas/GitHub/TFG/Procesamiento de modelos/results/HeadSpace-final\n",
      "results/HeadSpace-final/modelo_1213/131117171526\n",
      "results/HeadSpace-final/modelo_661/131020171933\n",
      "results/HeadSpace-final/modelo_900/131102112105\n",
      "results/HeadSpace-final/modelo_398/131006165343\n",
      "results/HeadSpace-final/modelo_1183/131116162124\n",
      "results/HeadSpace-final/modelo_930/131102153205\n",
      "results/HeadSpace-final/modelo_243/131003131855\n",
      "results/HeadSpace-final/modelo_1048/131109141827\n",
      "results/HeadSpace-final/modelo_853/131031152235\n",
      "results/HeadSpace-final/modelo_254/131003153402\n",
      "results/HeadSpace-final/modelo_208/131002123122\n",
      "results/HeadSpace-final/modelo_461/131011153026\n",
      "results/HeadSpace-final/modelo_743/131025160633\n",
      "results/HeadSpace-final/modelo_328/131005131034\n",
      "results/HeadSpace-final/modelo_1145/131115132726\n",
      "results/HeadSpace-final/modelo_950/131103140728\n",
      "results/HeadSpace-final/modelo_879/131101145747\n",
      "results/HeadSpace-final/modelo_678/131022174534\n",
      "results/HeadSpace-final/modelo_81/130928120730\n",
      "results/HeadSpace-final/modelo_43/130926183734\n"
     ]
    }
   ],
   "source": [
    "archivos = []\n",
    "ruta_carpeta = os.getcwd() + \"/results/HeadSpace-final\"\n",
    "\n",
    "print(ruta_carpeta)\n",
    "# ruta_carpeta = os.getcwd()\n",
    "for root , _, archs in os.walk(ruta_carpeta):\n",
    "    for archivo in archs:\n",
    "        # Verificar si el archivo tiene la extensión .obj\n",
    "        if archivo.endswith(\".obj\"):\n",
    "            ruta_archivo = os.path.join(root, archivo)\n",
    "            nombre, extension = os.path.splitext(ruta_archivo)\n",
    "            ruta_relativa = os.path.relpath(nombre, os.getcwd())\n",
    "            archivos.append(ruta_relativa)\n",
    "            print(ruta_relativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/HeadSpace-final/modelo_1213/131117171526.obj\n",
      "results/HeadSpace-final/modelo_661/131020171933.obj\n",
      "results/HeadSpace-final/modelo_900/131102112105.obj\n",
      "results/HeadSpace-final/modelo_398/131006165343.obj\n",
      "results/HeadSpace-final/modelo_1183/131116162124.obj\n",
      "results/HeadSpace-final/modelo_930/131102153205.obj\n",
      "results/HeadSpace-final/modelo_243/131003131855.obj\n",
      "results/HeadSpace-final/modelo_1048/131109141827.obj\n",
      "results/HeadSpace-final/modelo_853/131031152235.obj\n",
      "results/HeadSpace-final/modelo_254/131003153402.obj\n",
      "results/HeadSpace-final/modelo_208/131002123122.obj\n",
      "results/HeadSpace-final/modelo_461/131011153026.obj\n",
      "results/HeadSpace-final/modelo_743/131025160633.obj\n",
      "results/HeadSpace-final/modelo_328/131005131034.obj\n",
      "results/HeadSpace-final/modelo_1145/131115132726.obj\n",
      "results/HeadSpace-final/modelo_950/131103140728.obj\n",
      "results/HeadSpace-final/modelo_879/131101145747.obj\n",
      "results/HeadSpace-final/modelo_678/131022174534.obj\n",
      "results/HeadSpace-final/modelo_81/130928120730.obj\n",
      "results/HeadSpace-final/modelo_43/130926183734.obj\n"
     ]
    }
   ],
   "source": [
    "for archivo in archivos:\n",
    "    # Ruta del archivo .obj\n",
    "    obj_file_path = archivo + \".obj\"\n",
    "    pp_file_path = archivo + \".pp\"\n",
    "    # texture_file_path = archivo  + \".bmp\"\n",
    "    parte_deseada = archivo.split(\"/\")[0:3]\n",
    "    resultado = \"/\".join(parte_deseada)\n",
    "    texture_file_path = resultado + \"/material_0.bmp\"\n",
    "\n",
    "    print(obj_file_path)\n",
    "\n",
    "    coord_obj = obtener_coordenadas(obj_file_path, texture_file_path, pp_file_path)\n",
    "\n",
    "    v0 = list(zip(*coord_ref))\n",
    "    v1 = list(zip(*coord_obj))\n",
    "    matriz_transformacion = trimesh.transformations.affine_matrix_from_points(v0, v1, shear=False,scale=False)\n",
    "\n",
    "    for i in range(3):\n",
    "        matriz_transformacion[i][3] *= -1\n",
    "\n",
    "    # print(matriz_transformacion)\n",
    "\n",
    "    guardar_matriz_en_csv(obj_file_path, matriz_transformacion, archivo_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
